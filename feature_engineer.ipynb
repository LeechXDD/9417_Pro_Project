{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeechXDD/9417_Pro_Project/blob/main/feature_engineer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "!pip install tensorflow_addons\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow --upgrade\n",
        "!pip install --upgrade tensorflow-addons\n",
        "!pip install keras --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "myN3isf1CLXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "d0vQV4sDCN0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c predict-student-performance-from-game-play\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "id": "HLOQK5OLCRp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir kaggleData\n",
        "! unzip predict-student-performance-from-game-play.zip -d kaggleData\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m9kLkhfiCTA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_minimal_dtype(df):\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype.name\n",
        "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
        "            if (col_type != 'object'):\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "\n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        pass\n",
        "            else:\n",
        "                df[col] = df[col].astype('category')\n",
        "    mem_usg = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "HUAMsmXXCmBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('kaggleData/train.csv')\n",
        "test_data = pd.read_csv('kaggleData/test.csv')"
      ],
      "metadata": {
        "id": "VDt0x92nCmsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = get_minimal_dtype(train_data)"
      ],
      "metadata": {
        "id": "6wuoQ0L-z0AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in labels for training dataset\n",
        "labels = pd.read_csv('kaggleData/train_labels.csv')\n",
        "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
        "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
        "labels.head()"
      ],
      "metadata": {
        "id": "ir_J1IzXK3zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning\n",
        "The columns with missing values are:\n",
        "\n",
        "- page: This is only for notebook-related events. The missing values could indicate that the event is not related to the notebook. We could fill missing values with a placeholder like -1 to denote 'Not Applicable'.\n",
        "- room_coor_x, room_coor_y, screen_coor_x, screen_coor_y: These are the coordinates of the click, and are only relevant for click events. Similar to 'page', we could fill missing values with a placeholder.\n",
        "- hover_duration: This is only for hover events. We can use the same approach as for the coordinates.\n",
        "- text, fqid, text_fqid: These columns contain information about the event and the room. Missing values could indicate that the event does not involve any text or specific interactions that would be recorded in these fields. We could replace missing values with a placeholder like 'None' or 'Not Applicable'."
      ],
      "metadata": {
        "id": "PjJdKp1nzTrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out columns with missing values\n",
        "missing_values = train_data.isnull().sum()\n",
        "\n",
        "# Fill missing values\n",
        "train_data['page'].fillna(-1, inplace=True)\n",
        "train_data['room_coor_x'].fillna(-1, inplace=True)\n",
        "train_data['room_coor_y'].fillna(-1, inplace=True)\n",
        "train_data['screen_coor_x'].fillna(-1, inplace=True)\n",
        "train_data['screen_coor_y'].fillna(-1, inplace=True)\n",
        "train_data['hover_duration'].fillna(-1, inplace=True)"
      ],
      "metadata": {
        "id": "NLXBzjkgza29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "T8OXyNAuC0u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Create a function for easy plotting\n",
        "def plot_count(train_data, column, title, color, rotation=0):\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.countplot(data=train_data, x=column, order=train_data[column].value_counts().index, color=color)\n",
        "    plt.title(title, size=16)\n",
        "    plt.xticks(rotation=rotation)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "trc_KfkhC-k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of the Event Names\n",
        "The most common event in the dataset is 'navigate_click', followed by 'notification_click'. These events likely relate to key interactions within the game and could be influential in a model's ability to predict student performance."
      ],
      "metadata": {
        "id": "BjqwU2aU0DdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of event names\n",
        "plot_count(train_data, 'event_name', 'Distribution of Event Names', 'skyblue')"
      ],
      "metadata": {
        "id": "Ab8oSYGr0Bh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of Game Levels\n",
        "The distribution of game levels shows that the majority of the events are happening in the middle levels of the game (around level 10). This could suggest that most users progress to these levels before stopping, or that these levels simply have more interactive events."
      ],
      "metadata": {
        "id": "D16RPMP40Jsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of levels\n",
        "plot_count(train_data, 'level', 'Distribution of Game Levels', 'green')"
      ],
      "metadata": {
        "id": "gNU8Nha_0MAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of Level Groups\n",
        "The level group distribution shows that the majority of events belong to the '5-12' level group. This is consistent with the distribution of game levels, as the majority of events occurred at these levels."
      ],
      "metadata": {
        "id": "na93TK9O0OtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of level groups\n",
        "plot_count(train_data, 'level_group', 'Distribution of Level Groups', 'red')"
      ],
      "metadata": {
        "id": "2YqATkKg0RSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Elapsed Time Statistics\n",
        "From the histogram of 'elapsed_time', we can observe that the distribution is heavily skewed to the right, with a few sessions having unusually high elapsed time values. These could potentially be outliers or errors in the data."
      ],
      "metadata": {
        "id": "FzcqxIFw0U01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display statistics related to elapsed time\n",
        "elapsed_time_stats = train_data['elapsed_time'].describe()\n",
        "elapsed_time_stats\n",
        "\n",
        "# Plot the distribution of 'elapsed_time'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train_data['elapsed_time'], bins=100, color='purple')\n",
        "plt.title('Distribution of Elapsed Time', size=16)\n",
        "plt.xlabel('Elapsed Time (in milliseconds)', size=13)\n",
        "plt.ylabel('Count', size=13)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "52qQq1lS0XZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the table below it shows subset of the data that falls in the top 1% of 'elapsed_time' which could suggest outliers."
      ],
      "metadata": {
        "id": "_eSmK5PL0aWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the values on the high end of 'elapsed_time'\n",
        "high_elapsed_time = train_data[train_data['elapsed_time'] > train_data['elapsed_time'].quantile(0.99)]\n",
        "high_elapsed_time"
      ],
      "metadata": {
        "id": "rw6Se6EC0cpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So I will set all 'elapsed_time' values above the 99th percentile to the 99th percentile value. This would limit the effect of extreme values without completely removing them from the dataset."
      ],
      "metadata": {
        "id": "r8YA5kx-0hv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cap 'elapsed_time' at the 99th percentile\n",
        "train_data['elapsed_time'] = train_data['elapsed_time'].clip(upper=train_data['elapsed_time'].quantile(0.99))"
      ],
      "metadata": {
        "id": "9WmjsC7p0jtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum value is now significantly lower than before, while the other statistics (mean, standard deviation, etc.) remain similar. This means that the extreme high values have been limited, which should help to reduce their influence on the model."
      ],
      "metadata": {
        "id": "xHgjPsl10mnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the change\n",
        "train_data['elapsed_time'].describe()"
      ],
      "metadata": {
        "id": "QzIwouS40pHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "4yCD-5u3DTyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "def feature_engineer(dataset_df):\n",
        "    dfs = []\n",
        "    for c in CATEGORICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
        "        tmp.name = tmp.name + '_nunique'\n",
        "        dfs.append(tmp)\n",
        "    for c in NUMERICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
        "        dfs.append(tmp)\n",
        "    for c in NUMERICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
        "        tmp.name = tmp.name + '_std'\n",
        "        dfs.append(tmp)\n",
        "    dataset_df = pd.concat(dfs,axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "    return dataset_df\n",
        "\n"
      ],
      "metadata": {
        "id": "7_7xuf2CDVhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improved version of feature engineering function"
      ],
      "metadata": {
        "id": "i_Z1hMVP5AtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "BINNING = ['elapsed_time', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "# Define feature engineering function\n",
        "def feature_engineer_ver2(dataset_df):\n",
        "    dfs = []\n",
        "    for c in CATEGORICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
        "        tmp.name = c + '_nunique'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    for c in NUMERICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
        "        tmp.name = c + '_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Compute standard deviation only for certain features\n",
        "        if c in BINNING:\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
        "            tmp.name = c + '_std'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "        # Binning\n",
        "        if c in BINNING:  # Check if column is in the list of columns to bin\n",
        "            dataset_df[c+'_bin'] = pd.qcut(dataset_df[c], q=4, duplicates='drop')\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c+'_bin'].agg('count')\n",
        "            tmp.name = c + '_bin_count'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "    # Interaction between screen coordinates\n",
        "    if 'screen_coor_x' in NUMERICAL and 'screen_coor_y' in NUMERICAL:\n",
        "        # Compute Euclidean distance instead of product\n",
        "        dataset_df['screen_coor'] = np.sqrt(dataset_df['screen_coor_x']**2 + dataset_df['screen_coor_y']**2)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['screen_coor'].agg(['mean', 'std'])\n",
        "        tmp.columns = ['screen_coor_mean', 'screen_coor_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    # Aggregated features\n",
        "    if 'hover_duration' in NUMERICAL:\n",
        "        dataset_df['total_hover_duration'] = dataset_df.groupby(['session_id'])['hover_duration'].transform('sum')\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['total_hover_duration'].agg('mean')\n",
        "        tmp.name = 'total_hover_duration_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    dataset_df = pd.concat(dfs,axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "\n",
        "    dataset_df['screen_coor_mean'] = dataset_df['screen_coor_mean'].astype('int32')\n",
        "    for col in dataset_df.select_dtypes(include='float16').columns:\n",
        "        dataset_df[col] = dataset_df[col].astype('float32')\n",
        "\n",
        "    return dataset_df\n"
      ],
      "metadata": {
        "id": "BJdil45xc-BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "BINNING = ['elapsed_time', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "def feature_engineer_ver3(dataset_df):\n",
        "    dfs = []\n",
        "    pt = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "    for c in CATEGORICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
        "        tmp.name = c + '_nunique'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Create dummy variables for top N most common events and names\n",
        "        top_N = dataset_df[c].value_counts()[:10].index\n",
        "        for val in top_N:\n",
        "            dataset_df[c + '_' + val] = (dataset_df[c] == val).astype(int)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group']).agg({c + '_' + val: 'sum' for val in top_N})\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    for c in NUMERICAL:\n",
        "        # Fill missing values with the column median\n",
        "        dataset_df[c].fillna(dataset_df[c].median(), inplace=True)\n",
        "\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
        "        tmp.name = c + '_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Compute standard deviation only for certain features\n",
        "        if c in BINNING:\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
        "            tmp.name = c + '_std'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "        # Normalize 'elapsed_time' column\n",
        "        if c == 'elapsed_time':\n",
        "            dataset_df[c] = pt.fit_transform(dataset_df[[c]])\n",
        "\n",
        "        # Binning\n",
        "        if c in BINNING:  # Check if column is in the list of columns to bin\n",
        "            dataset_df[c+'_bin'] = pd.qcut(dataset_df[c], q=4, duplicates='drop')\n",
        "            #dataset_df[c+'_bin'] = pd.qcut(dataset_df[c], q=4, duplicates='drop').astype('category')\n",
        "\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c+'_bin'].agg('count')\n",
        "            tmp.name = c + '_bin_count'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "    # Interaction between screen coordinates\n",
        "    if 'screen_coor_x' in NUMERICAL and 'screen_coor_y' in NUMERICAL:\n",
        "        # Compute Euclidean distance instead of product\n",
        "        dataset_df['screen_coor'] = np.sqrt(dataset_df['screen_coor_x']**2 + dataset_df['screen_coor_y']**2)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['screen_coor'].agg(['mean', 'std'])\n",
        "        tmp.columns = ['screen_coor_mean', 'screen_coor_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    # Aggregated features\n",
        "    if 'hover_duration' in NUMERICAL:\n",
        "        dataset_df['total_hover_duration'] = dataset_df.groupby(['session_id'])['hover_duration'].transform('sum')\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['total_hover_duration'].agg('mean')\n",
        "        tmp.name = 'total_hover_duration_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    dataset_df = pd.concat(dfs, axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "\n",
        "    return dataset_df\n",
        "\n"
      ],
      "metadata": {
        "id": "sBcKrSUmqn5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "             'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "def feature_engineer_ver4(dataset_df):\n",
        "    dfs = []\n",
        "    le = LabelEncoder()\n",
        "    discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
        "\n",
        "    for c in CATEGORICAL:\n",
        "        # Label encoding for categorical features\n",
        "        dataset_df[c+'_encoded'] = le.fit_transform(dataset_df[c].astype(str))\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c+'_encoded'].agg(['mean', 'std'])\n",
        "        tmp.columns = [c + '_encoded_mean', c + '_encoded_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    for c in NUMERICAL:\n",
        "        # Fill missing values with the column median\n",
        "        dataset_df[c].fillna(dataset_df[c].median(), inplace=True)\n",
        "\n",
        "        # Calculate sum, mean and std for numerical features\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg(['sum', 'mean', 'std'])\n",
        "        tmp.columns = [c + '_sum', c + '_mean', c + '_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Apply binning to numerical features\n",
        "        dataset_df[c+'_binned'] = discretizer.fit_transform(dataset_df[[c]])\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c+'_binned'].agg(['mean', 'std'])\n",
        "        tmp.columns = [c + '_binned_mean', c + '_binned_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    # Interaction between screen coordinates\n",
        "    if 'screen_coor_x' in NUMERICAL and 'screen_coor_y' in NUMERICAL:\n",
        "        # Compute Euclidean distance instead of product\n",
        "        dataset_df['screen_coor'] = np.sqrt(dataset_df['screen_coor_x']**2 + dataset_df['screen_coor_y']**2)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['screen_coor'].agg(['sum', 'mean', 'std'])\n",
        "        tmp.columns = ['screen_coor_sum', 'screen_coor_mean', 'screen_coor_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    # Aggregated features\n",
        "    if 'hover_duration' in NUMERICAL:\n",
        "        dataset_df['total_hover_duration'] = dataset_df.groupby(['session_id'])['hover_duration'].transform('sum')\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['total_hover_duration'].agg(['mean', 'std'])\n",
        "        tmp.columns = ['total_hover_duration_mean', 'total_hover_duration_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    dataset_df = pd.concat(dfs, axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "\n",
        "    dataset_df['page_sum'] = dataset_df['page_sum'].astype('int32')\n",
        "    for col in dataset_df.select_dtypes(include='float16').columns:\n",
        "        dataset_df[col] = dataset_df[col].astype('float32')\n",
        "\n",
        "    return dataset_df\n"
      ],
      "metadata": {
        "id": "iSRzuo6Pz_xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def feature_engineer_ver5(data):\n",
        "    # Encode categorical variables\n",
        "    categorical_cols = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
        "    encoder = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        data[col] = encoder.fit_transform(data[col])\n",
        "\n",
        "    # Generate historical features\n",
        "    # Here we calculate the average elapsed_time for all previous events in the same session\n",
        "    data['avg_elapsed_time'] = data.groupby('session_id')['elapsed_time'].transform('mean')\n",
        "\n",
        "    # You can add more historical features as needed\n",
        "    # For example, count the number of 'navigate_click' events for each session\n",
        "    data['navigate_click_count'] = data[data['event_name'] == 'navigate_click'].groupby('session_id')['event_name'].transform('count')\n",
        "\n",
        "    # Or calculate the maximum hover_duration for each session\n",
        "    data['max_hover_duration'] = data.groupby('session_id')['hover_duration'].transform('max')\n",
        "    # Count of each event type\n",
        "    event_counts = data.groupby('session_id')['event_name'].value_counts().unstack(fill_value=0)\n",
        "    data = data.join(event_counts, on='session_id')\n",
        "\n",
        "    # Time since the last event\n",
        "    data['time_since_last_event'] = data.groupby('session_id')['elapsed_time'].diff()\n",
        "\n",
        "    # Number of events in fullscreen mode\n",
        "    data['fullscreen_event_count'] = data[data['fullscreen'] == 1].groupby('session_id')['fullscreen'].transform('count')\n",
        "\n",
        "    # Number of events with music on\n",
        "    data['music_event_count'] = data[data['music'] == 1].groupby('session_id')['music'].transform('count')\n",
        "\n",
        "    # Number of unique levels played\n",
        "    data['unique_levels_count'] = data.groupby('session_id')['level'].transform('nunique')\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "XycLQKKSDFha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test run on sample of dataset *****************"
      ],
      "metadata": {
        "id": "dq1FgjHf1HXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample = train_data.sample(frac=0.05)\n",
        "#dataset_df = feature_engineer(train_data)\n",
        "#dataset_df = feature_engineer_ver2(train_data)\n",
        "#dataset_df = feature_engineer_ver3(sample)\n",
        "#dataset_df = feature_engineer_ver4(train_data)\n",
        "dataset_df = feature_engineer_ver5(train_data)\n",
        "\n",
        "#Also, remember to apply the same transformations to your test data.\n",
        "#test_data = feature_engineer_ver4(test_data)"
      ],
      "metadata": {
        "id": "_xIA59za1Ggx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace `inf` values:\n",
        "dataset_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Replace `NaN` values with column mean:\n",
        "dataset_df.fillna(dataset_df.mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "QetN3gZ1Uqrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trial Run on Model"
      ],
      "metadata": {
        "id": "HnMoEEfcR28p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow --upgrade\n",
        "!pip install keras --upgrade\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf"
      ],
      "metadata": {
        "id": "xUDLJ-mql3pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, test_ratio=0.20):\n",
        "    USER_LIST = dataset.index.unique()\n",
        "    split = int(len(USER_LIST) * (1 - 0.20))\n",
        "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
        "\n",
        "train_x, valid_x = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples in testing.\".format(\n",
        "    len(train_x), len(valid_x)))"
      ],
      "metadata": {
        "id": "ivvsKUsQmBP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.keras.get_all_models()"
      ],
      "metadata": {
        "id": "ERK5HigemEb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fetch the unique list of user sessions in the validation dataset. We assigned\n",
        "# `session_id` as the index of our feature engineered dataset. Hence fetching\n",
        "# the unique values in the index column will give us a list of users in the\n",
        "# validation set.\n",
        "VALID_USER_LIST = valid_x.index.unique()\n",
        "\n",
        "# Create a dataframe for storing the predictions of each question for all users\n",
        "# in the validation set.\n",
        "# For this, the required size of the data frame is:\n",
        "# (no: of users in validation set  x no of questions).\n",
        "# We will initialize all the predicted values in the data frame to zero.\n",
        "# The dataframe's index column is the user `session_id`s.\n",
        "prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
        "\n",
        "# Create an empty dictionary to store the models created for each question.\n",
        "models = {}\n",
        "\n",
        "# Create an empty dictionary to store the evaluation score for each question.\n",
        "evaluation_dict ={}\n"
      ],
      "metadata": {
        "id": "9TTcvgPDmHgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for q_no in range(1,19):\n",
        "\n",
        "    # Select level group for the question based on the q_no.\n",
        "    if q_no<=3: grp = '0-4'\n",
        "    elif q_no<=13: grp = '5-12'\n",
        "    elif q_no<=22: grp = '13-22'\n",
        "    print(\"### q_no\", q_no, \"grp\", grp)\n",
        "\n",
        "\n",
        "    # Filter the rows in the datasets based on the selected level group.\n",
        "    train_df = train_x.loc[train_x.level_group == grp]\n",
        "    train_users = train_df.index.values\n",
        "    valid_df = valid_x.loc[valid_x.level_group == grp]\n",
        "    valid_users = valid_df.index.values\n",
        "\n",
        "    # Select the labels for the related q_no.\n",
        "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
        "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
        "\n",
        "\n",
        "    # Add the label to the filtered datasets.\n",
        "    train_df[\"correct\"] = train_labels[\"correct\"]\n",
        "    valid_df[\"correct\"] = valid_labels[\"correct\"]\n",
        "\n",
        "    # There's one more step required before we can train the model.\n",
        "    # We need to convert the datatset from Pandas format (pd.DataFrame)\n",
        "    # into TensorFlow Datasets format (tf.data.Dataset).\n",
        "    # TensorFlow Datasets is a high performance data loading library\n",
        "    # which is helpful when training neural networks with accelerators like GPUs and TPUs.\n",
        "    # We are omitting `level_group`, since it is not needed for training anymore.\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df.loc[:, train_df.columns != 'level_group'], label=\"correct\")\n",
        "    valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df.loc[:, valid_df.columns != 'level_group'], label=\"correct\")\n",
        "\n",
        "    # We will now create the Gradient Boosted Trees Model with default settings.\n",
        "    # By default the model is set to train for a classification task.\n",
        "    gbtm = tfdf.keras.RandomForestModel(verbose=0)\n",
        "    gbtm.compile(metrics=[\"accuracy\"])\n",
        "    # Train the model.\n",
        "    gbtm.fit(x=train_ds)\n",
        "\n",
        "    # Store the model\n",
        "    models[f'{grp}_{q_no}'] = gbtm\n",
        "\n",
        "    # Evaluate the trained model on the validation dataset and store the\n",
        "    # evaluation accuracy in the `evaluation_dict`.\n",
        "    inspector = gbtm.make_inspector()\n",
        "    inspector.evaluation()\n",
        "    evaluation = gbtm.evaluate(x=valid_ds,return_dict=True)\n",
        "    evaluation_dict[q_no] = evaluation[\"accuracy\"]\n",
        "\n",
        "    # Use the trained model to make predictions on the validation dataset and\n",
        "    # store the predicted values in the `prediction_df` dataframe.\n",
        "    predict = gbtm.predict(x=valid_ds)\n",
        "    prediction_df.loc[valid_users, q_no-1] = predict.flatten()"
      ],
      "metadata": {
        "id": "gFcU7TIymJty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, value in evaluation_dict.items():\n",
        "  print(f\"question {name}: accuracy {value:.4f}\")\n",
        "\n",
        "print(\"\\nAverage accuracy\", sum(evaluation_dict.values())/18)"
      ],
      "metadata": {
        "id": "O4PHtSoGoDIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspector = models['0-4_1'].make_inspector()\n",
        "\n",
        "print(f\"Available variable importances:\")\n",
        "for importance in inspector.variable_importances().keys():\n",
        "  print(\"\\t\", importance)\n",
        "inspector.variable_importances()[\"NUM_AS_ROOT\"]"
      ],
      "metadata": {
        "id": "BB31eZTgoGSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score  0.6319707 (feature_engineer)\n",
        "# F1 score  0.64316726 (feature_engineer_ver2)\n",
        "# F1 score  0.64058185 (feature_engineer_ver4)\n",
        "\n",
        "true_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
        "for i in range(18):\n",
        "    # Get the true labels.\n",
        "    tmp = labels.loc[labels.q == i+1].set_index('session').loc[VALID_USER_LIST]\n",
        "    true_df[i] = tmp.correct.values\n",
        "\n",
        "max_score = 0; best_threshold = 0\n",
        "\n",
        "# Loop through threshold values from 0.4 to 0.8 and select the threshold with\n",
        "# the highest `F1 score`.\n",
        "# using uniform threashold = 0.5 for the baseline\n",
        "\n",
        "\n",
        "# for threshold in np.arange(0.4,0.8,0.01):\n",
        "#     metric = tf.keras.metrics.F1Score(average=\"macro\",threshold=threshold)\n",
        "#     y_true = tf.one_hot(true_df.values.reshape((-1)), depth=2)\n",
        "#     y_pred = tf.one_hot((prediction_df.values.reshape((-1))>threshold).astype('int'), depth=2)\n",
        "#     metric.update_state(y_true, y_pred)\n",
        "#     f1_score = metric.result().numpy()\n",
        "#     if f1_score > max_score:\n",
        "#         max_score = f1_score\n",
        "#         best_threshold = threshold\n",
        "metric = tf.keras.metrics.F1Score(average=\"macro\",threshold=0.5)\n",
        "y_true = tf.one_hot(true_df.values.reshape((-1)), depth=2)\n",
        "y_pred = tf.one_hot((prediction_df.values.reshape((-1))>0.5).astype('int'), depth=2)\n",
        "metric.update_state(y_true, y_pred)\n",
        "f1_score = metric.result().numpy()\n",
        "\n",
        "\n",
        "print(\"threshold \", 0.5, \"\\tF1 score \", f1_score)"
      ],
      "metadata": {
        "id": "T0Yr90iroJND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}